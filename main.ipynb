{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from constants import NP_SEED, TF_SEED\n",
    "np.random.seed(NP_SEED)\n",
    "tf.set_random_seed(TF_SEED)\n",
    "\n",
    "from nn_clf import CNN_to_RNN, Dense, RAND_CNN, RNN\n",
    "import etl\n",
    "import util\n",
    "from visualizer import plot_metrics\n",
    "from ensembler import Ensembler\n",
    "\n",
    "N_CLASS = 3\n",
    "N_LOOKBACK = 8\n",
    "SPLIT_RATIO = (0.7, 0.15, 0.15)  # train, val, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1. Data Extract, Transform and Load\n",
    "랜덤 시드 변경을 적용하려면, reload=True로 설정해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load dataset from existing dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yongwoo/anaconda3/envs/ipykernel_py36/lib/python3.6/site-packages/IPython/core/magics/execution.py:1238: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code, glob, local_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  train   x (4616, 8, 249)\n",
      "  train   y (4616, 1)\n",
      "  train  dt (4616,)\n",
      "    val   x (0,)\n",
      "    val   y (0, 1)\n",
      "    val  dt (0,)\n",
      "   test   x (0,)\n",
      "   test   y (0, 1)\n",
      "   test  dt (0,)\n",
      "problem   x (600, 8, 249)\n",
      "problem  dt (600,)\n",
      "\n",
      "[train data 분포]\n",
      "0 : 1 : 2 = 0.45 : 0.55 : 0.0\n",
      "[val data 분포]\n",
      "0 : 1 : 2 = nan : nan : nan\n",
      "[test data 분포]\n",
      "0 : 1 : 2 = nan : nan : nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yongwoo/AI-Hackerton/Posco-ai-challnege/0830_last/etl.py:54: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  print('0 : 1 : 2 = {:.2} : {:.2} : {:.2}'.format((d0_dict['y'] == 0).sum() / len(d0_dict['y']),\n",
      "/home/yongwoo/AI-Hackerton/Posco-ai-challnege/0830_last/etl.py:55: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  (d0_dict['y'] == 1).sum() / len(d0_dict['y']),\n",
      "/home/yongwoo/AI-Hackerton/Posco-ai-challnege/0830_last/etl.py:56: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  (d0_dict['y'] == 2).sum() / len(d0_dict['y'])))\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "etler = etl.ETL(N_LOOKBACK, SPLIT_RATIO, downsampling=False, reload=False)\n",
    "\n",
    "# val과 test 데이터에서 swell_t-1과 맞춰야하는 swell이 다른 샘플 개수 출력\n",
    "print((etler.ds['val']['x'][:, -1, -1] != etler.ds['val']['y'][:, -1]).sum())\n",
    "print((etler.ds['test']['x'][:, -1, -1] != etler.ds['test']['y'][:, -1]).sum())\n",
    "\n",
    "# train 데이터에서 swell_t-1과 맞춰야하는 swell이 다른 샘플들을 오버샘플링\n",
    "etler.oversampling(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2. Build Neural Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf 그래프 초기화 및 세션 생성\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "BATCH_SIZE = 64\n",
    "N_FEATURE = etler.ds['train']['x'].shape[-1]\n",
    "N_ENSEMBLE = 1\n",
    "EPOCH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn_list = []  # 앙상블 할 모델들의 리스트\n",
    "predicts_list = [] # 각 모델의 predicts(val,test,problem에 대한 epoch당 예측결과)의 리스트\n",
    "# for i in range(N_ENSEMBLE): # 앙상블 할 모델들의 그래프 생성(build)\n",
    "#     nn = Dense(sess, N_CLASS, N_LOOKBACK, N_FEATURE, \n",
    "#                dropout_keep_prob=0.5,\n",
    "#                lr=1e-4,\n",
    "#                lr_decay=0.90,\n",
    "# #                feature_size_list=etler.feature_size_list,\n",
    "#                name='dense'+str(i))\n",
    "#     nn_list.append(nn)\n",
    "    \n",
    "for i in range(N_ENSEMBLE): # 앙상블 할 모델들의 그래프 생성(build)\n",
    "    nn = RAND_CNN(sess, N_CLASS, N_LOOKBACK, N_FEATURE, \n",
    "               dropout_keep_prob=0.5,\n",
    "               lr=1e-4,\n",
    "               lr_decay=0.90,\n",
    "#                feature_size_list=etler.feature_size_list,\n",
    "               name='CNN'+str(i))\n",
    "    nn_list.append(nn)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3. Model Ensemble and Save the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembler = Ensembler(etler.ds, BATCH_SIZE, EPOCH, \n",
    "                        feature_shuffle=True, # swell_t-1를 제외한 피쳐 셔플 여부\n",
    "                        train_all_data=False, # val, test 데이터를 학습에 사용할 지 여부\n",
    "                        nn_list=nn_list\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ensembler.train_per_nn()  # nn 하나 EPOCH 학습 후, 다음 nn 학습\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step X. 한 모델만 돌려보는 경우 아래 코드 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tf 그래프 초기화 및 세션 생성\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "BATCH_SIZE = 64\n",
    "N_FEATURE = etler.ds['train']['x'].shape[-1]\n",
    "N_ENSEMBLE = 3\n",
    "EPOCH = 30\n",
    "#RAND_CNN\n",
    "nn = CNN_to_RNN(sess, N_CLASS, N_LOOKBACK, N_FEATURE, \n",
    "           dropout_keep_prob=0.5,\n",
    "           lr=3e-5,\n",
    "           lr_decay=0.95,\n",
    "           feature_size_list=etler.feature_size_list,\n",
    "           name='nn')\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "predicts = nn.train(etler.ds, BATCH_SIZE, EPOCH, \n",
    "                    feature_shuffle=False, # swell_t-1를 제외한 피쳐 셔플 여부\n",
    "                    train_all_data=False, # val, test 데이터를 학습에 사용할 지 여부\n",
    "                    verbose=True\n",
    "                    )\n",
    "\n",
    "#util.save_result_excel(predicts['problem'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow36",
   "language": "python",
   "name": "py36_tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
